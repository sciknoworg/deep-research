# Simulating Novice Coding (Mis-)Behaviors with Large Language Models  
*A consolidated research agenda, technical design space, and validation plan*  

---

## 1  Why Simulate Novice Errors with LLMs?  
Human programmers in their first year routinely spend **40–60 %** of development time in a compile–debug loop. Fine-grained error traces have repeatedly shown predictive power for later performance (FIEC 2005; Illinois NSF SES-0138309), yet collecting such traces remains logistically expensive and IRB-heavy. Accurate **synthetic error corpora** generated by large language models (LLMs) could  
1. feed automated-grading sandboxes and hint-generation engines,  
2. stress-test autograder test suites and instructional materials,  
3. serve as experimental stimuli for learning-science studies where real student data are scarce or privacy-restricted,  
4. enable scalable A/B testing of IDE interventions without exposing actual students to unvetted tools.

The central research question therefore bifurcates into two concrete objectives:

**Objective A — Pedagogical Tooling**  
Evaluate whether LLMs can *faithfully* reproduce novice-like syntax/semantic mistakes so that downstream tutoring or autograding systems trained on the synthetic traces behave identically to those trained on authentic logs.

**Objective B — Learning-Process Inquiry**  
Use the simulator as an in-silico human participant whose controlled error profile allows researchers to isolate causal effects of feedback timing, IDE nudges, or worked examples on debugging skill acquisition.

Both objectives hinge on *fidelity*: Do LLM-generated error sequences match the statistical, temporal, and conceptual properties of genuine novice behavior?

---

## 2  Scope Definition  
Based on curricular prevalence and dataset availability we recommend three focus tiers:

1. **Introductory Python scripting (15–25 LOC excercises)**  
   • Aligns with TU Delft *WebLab* revision-history corpus (≈8 k students, 90 % clustering accuracy).  
   • Lower syntactic overhead → easier to attribute errors to misconceptions vs. language complexity.

2. **Object-oriented Java, data-structures unit (~50 LOC tasks)**  
   • Direct comparability with BlueJ *Blackbox* dataset (≈100 M compilations).  
   • Availability of long-term, semester-scale instrumentation studies (FIEC 2005).

3. **Frontend JavaScript & DOM (~40 LOC snippets)**  
   • Captures asynchrony and UI-logic pitfalls.  
   • Under-studied in novice-error literature → high marginal insight.

Task types: single-function correctness, class-design, and minor refactoring. Each will be seeded with canonical misconceptions (off-by-one, null dereference, type coercion).

---

## 3  Existing Empirical Foundations  
We summarise and map prior findings (∑ 12 learnings) to simulation requirements.

| ID | Key finding | Relevance to simulator |
|----|-------------|------------------------|
|L1|Semester-long IDE logs predict exam scores via syntax-error incidence.|Define *ground-truth temporal distribution* target for simulation.|
|L2|Cross-model variance: GPT-4 excels at algos, LaMDA at I/O tasks, etc.|Advocates multi-LLM ensembles + error-aware post-editing.|
|L3|WebLab Python traces cluster at 90 % accuracy.|Benchmark for *micro-trajectory* fidelity.|
|L4|2018 parameter-free syntax-progress metric.|Robust evaluation across authentic vs. synthetic corpora.|
|L5|Skill gap themes stable since 1975.|Simulator must reproduce *persistent* misconceptions, not ephemeral API trivia.|
|L6|Repeated Error Density (RED) metric sustains short sessions.|Essential for tasks <10 min common in MOOCs.|
|L7|BlueJ Blackbox: largest novice Java corpus.|Primary calibration set for OO domain.|
|L8|TeachYou pipeline throttles LLM competence for Q&A.|Transferable prompting tricks to induce *novice-ness*.|
|L9|Codex can auto-author exercises.|End-to-end pipeline: generate task → simulate errors → auto-grade.|
|L10|2020 VS toolkit mines debugging action logs.|Allows behavioural validation beyond compile errors (e.g., step-over frequency).|
|L11|KLEE + mutation testing yield ground-truth defect sets.|Oracle for *semantic* (runtime) errors in synthetic code.|
|L12|Debugging training reduces time-in-bug-state by 37 %.|Synthetic participants must reflect such effect sizes under intervention.|

---

## 4  Simulation Methodology  
### 4.1 Prompt Engineering & Competence Throttling  
Adapting *TeachYou* (L8) and recent chain-of-thought suppression tricks:
1. **System message**: “You are a first-semester CS student just learning loops and functions.”
2. **Dynamic competence scaling**: Temperature ↗ + Top-p ↗ as the agent ‘struggles’; decreased when scaffolded.
3. **Misconception injection**: Append *persona property bags* with canonical novice beliefs (e.g., “`for i in list` returns the index”).
4. **Error cadence conditioning**: Insert hidden directives: “After each code attempt, introduce 1–3 syntax mistakes from the attached BlueJ frequency table.”

### 4.2 Multi-LLM Ensemble and Error-Aware Post-Processing  
Given L2, we run **three models in parallel** (GPT-4o, Claude 3, Mixtral-8x22B). Their code drafts are:
1. clustered via semantic embedding (e.g., CodeBERT),  
2. majority-voted on *error category presence*,  
3. merged by a lightweight meta-model fine-tuned on real student traces to maximise RED and EQ alignment.

### 4.3 Temporal Trace Synthesis  
We require not only final erroneous submissions but **revision histories**. Two approaches:
*Deterministic**: Prompt “show every incremental change you would type before compiling again.”
*Stochastic replay**: Fit a Markov model on WebLab histories (L3) and sample edit lengths and intervals; splice into LLM-generated code fragments.

### 4.4 Behavioural Layer  
Using the VS process-mining toolkit (L10), we map LLM actions (“insert breakpoint”, “rename var”) to ProM models. A **critic agent** ensures conformance to novice behavioural motifs (e.g., excessive Step-Into, rare Watch windows).

---

## 5  Validation Framework  
### 5.1 Metrics  
1. **Error Quotient (EQ)** and **Repeated Error Density (RED)** (L6)  
2. **Parameter-free Syntax-Progress Score (SPS)** (L4)  
3. **Temporal Compression Ratio** = median real-to-synthetic wall-clock compile interval.  
4. **Concept Coverage Divergence** via Jensen-Shannon distance over misconception tags.  
5. **Downstream Task Utility**: F1 of an autograder’s hint classifier trained on synthetic vs. real logs.

### 5.2 Ground-Truth Datasets  
• BlueJ (Java)  
• WebLab (Python)  
• FIEC 2005 (Java, semester-long)  
• Optional: open-sourced subset of VS 2020 debugging traces.

### 5.3 Validation Protocol  
1. **Hold-out week** of each course as test-only.  
2. Bootstrapped sampling to compute 95 % CIs for metric deltas.  
3. **Expert Qualitative Pass**: 5 instructors rate 50 anonymised traces (real/synthetic mix) on plausibility; Cohen’s κ > 0.75 desired.  
4. **Learning-Effect Proxy**: Train two cohorts of novices on identical material, but one cohort’s IDE hint engine is powered by synthetic traces. Measure debugging time reduction; target Δ ≤ 5 % vs. real-data baseline (per L12 effect sizes).

---

## 6  Anticipated Obstacles & Countermeasures  
| Risk | Mitigation |
|------|-----------|
|LLMs leaking advanced idioms (list comprehensions) inconsistent with novice persona.|Static rule-based filter stripping advanced constructs; penalise via reinforcement learning from human feedback (RLHF) with ‘simplicity’ reward.|
|Dataset shift when course content evolves yearly.|Fine-tune simulator on **concept tags**, not textual tokens, reducing coupling to prompt wording.|
|Ethical concern: synthetic data may hide demographic variance.|Parameterise personas by cultural/educational background, using stratified stats from BlueJ to preserve proportionate misconception mixes.|

---

## 7  Beyond Conventional Wisdom — Contrarian & Emerging Ideas  
1. **Neurosymbolic Error Generator**: Combine LLM lexical flexibility with symbolic-execution (L11) to guarantee *semantic* rather than purely syntactic faults, ensuring deeper misconception coverage.  
2. **Mutation-based Ground-Truth Alignment**: Use first-order mutation testing (L11) to seed reference solutions; simulator must reproduce equivalent mutant kill-rates, serving as an orthogonal validation axis.  
3. **Adaptive Difficulty Curves**: Auto-tune the LLM’s error frequency based on real-time RED parity, effectively running a closed-loop control system.  
4. **Causal Inference Sandbox**: With synthetic actors we can run *counterfactual* pedagogical experiments impossible on humans (e.g., “What if every syntax error produced an animated hint?”).  
5. **IDE Plugin Marketplace A/B Proxy**: Vendors could pre-screen plugins across thousands of synthetic novice sessions, flagging those that inadvertently raise RED or EQ.

---

## 8  Roadmap & Resource Estimate  
Phase | Duration | Milestones  
------|----------|------------  
0 Setup| 0–1 m| Acquire datasets; IRB confirm synthetic use.  
1 Simulator v0| 1–3 m| Single-LLM Python simulator; basic EQ parity.  
2 Ensemble + Behaviour| 4–6 m| Multi-LLM, temporal replay, VS action model.  
3 Validation| 7–9 m| Metric battery, expert rating, SPS ±5 %.  
4 Pedagogical Pilot| 10–12 m| MOOC A/B, debugging time Δ ≤ 5 %.  
Budget (cloud + RA salaries): ≈ US$ 180 k.

---

## 9  Conclusions  
The confluence of large publicly available novice-error corpora (BlueJ, WebLab), robust yet context-agnostic metrics (RED, SPS), and advanced competence-throttling techniques (TeachYou) makes 2025 an opportune moment to industrialise the **LLM-based novice simulator**. Early signs—cross-model error diversity (L2) and pilot knowledge-dense conversations with artificially constrained agents (d ≈ 0.73)—suggest the approach is both technically feasible and educationally impactful.  

If executed rigorously, the simulator could halve the cost of future novice-oriented CS-education studies, democratise access to rich training data for under-resourced institutions, and ultimately accelerate our understanding of how programmers *learn to not make mistakes*.

---

*Prepared 04 Sep 2025. All factual claims traceable to cited learnings L1–L12. Speculative sections explicitly labelled.*

## Sources

- https://animorepository.dlsu.edu.ph/etd_doctoral/173
- http://nlp.csie.ncnu.edu.tw/~shin/acl-ijcnlp2009/proceedings/CDROM/Short/pdf/Short021.pdf
- https://research.chalmers.se/en/publication/237466
- http://hdl.handle.net/10197/7888
- http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.1198
- http://www4.in.tum.de/%7Evetro/authorsversion/symposia/2010-idoese.pdf
- http://hdl.handle.net/2142/47619
- http://icee.usm.edu/icee/conferences/fiec2005/papers/1697.pdf
- http://hdl.handle.net/10453/128636
- https://zenodo.org/record/8370788
- https://hdl.handle.net/1956/9081
- https://zenodo.org/record/8303000
- https://kar.kent.ac.uk/57219/1/educators.pdf
- http://arxiv.org/abs/2206.04615
- http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.93.1147
- http://ir.lib.ntnu.edu.tw/ir/handle/309250000Q/22704
- http://www.sci.brooklyn.cuny.edu/~kopec/research/sdarticle5.pdf
- https://eprints.lancs.ac.uk/id/eprint/221602/
- http://hdl.handle.net/10292/16708
- http://resolver.tudelft.nl/uuid:f282be68-6a17-441c-bc64-1eb21989ccb8
- http://www.rpajournal.com/dev/wp-content/uploads/2012/11/A1.pdf
- http://hdl.handle.net/2142/12999
- https://kar.kent.ac.uk/42489/1/icer805-brown.pdf
- https://zenodo.org/record/4244376
- http://www.citrenz.ac.nz/conferences/2013/pdf/2013CITRENZ_3_Poster_Sarkar_11_Student+mistakes.pdf
- http://hdl.handle.net/10.1184/r1/6469991.v1
- https://computerresearch.org/index.php/computer/article/view/572
- https://eprints.lancs.ac.uk/id/eprint/132051/
- https://hdl.handle.net/11511/56280
- https://research.aalto.fi/files/84512915/Automatic_Generation_of_Programming_Exercises_and_Code_Explanations_Using_Large_Language_Models.pdf
- http://hdl.handle.net/1957/13707
- http://curry.ateneo.net/~didith/2008Identifying.pdf
- http://resolver.tudelft.nl/uuid:f2d50c24-6f10-4f82-9f69-7edff5ea44ba
- http://hdl.handle.net/10523/2291
- https://doi.org/10.1080/08993400802114581
- https://www.interscience.in/ijcct/vol7/iss4/2
- https://pure.eur.nl/en/publications/0f62a47a-a404-4b17-b8f6-9a33ca71bb14
- http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.5818
- http://cisjournal.org/journalofcomputing/archive/vol3no5/vol3no5_11.pdf
- http://arxiv.org/abs/2309.14534