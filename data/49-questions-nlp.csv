title,problem statement
Robust Defenses against Many-Shot Jailbreaking,"Existing defenses against many-shot jailbreaking have significant flaws, necessitating the development of improved prompt-based defenses that maintain model helpfulness while enhancing safety."
Autoprompting: Generate Diverse Few-Shot Examples for Any Application,"Adding natural language capabilities to existing software requires manually crafting few-shot prompts, which is tedious and does not guarantee high coverage."
Probabilistic Opinion Pooling for Open-Domain Question Answering,Language models do not accurately reflect the uncertainty arising from conflicting evidence when answering questions.
A Compound LLM System to Mimic Knowledge Unlearning in Large Language Models,"Machine unlearning in large language models is a challenging problem. Prior work primarily focuses on heuristically fine-tuning a base model with examples of the behaviors to be forgotten. However, as base models become increasingly powerful, it is unclear whether mere prompting could be sufficient to induce a behavior that is safe and comparable to fine-tuning based unlearning for practical purposes, such as having a chatbot pretend to unlearn. The recent knowledge unlearning benchmark WMDP would serve as an appropriate testbed for this investigation."
Uncertainty Estimation via Consistency in Self-generated References in Large Language Models,"This research aims to develop a method for estimating uncertainty in the outputs of Large Language Models (LLMs) in an unsupervised manner. By associating each output with a confidence score, this method intends to enhance hallucination detection and its subsequent mitigation."
Chain-of-Compilers: Towards Faithful Code Understanding and Execution,Executing complex code generated from code generation models often leads to erroneous behavior. Can we leverage the discrete nature of code to execute multiple compilations to judge and improve the generated code?
Translation with LLMs through Prompting with Long-Form Context,Stable generation of text in low-resource languages is an unsolved issue in large language models.
Incorporating Chain-of-Context in Self-planning Enhances Interactive Code Generation from Natural Language,"Generating code implementation that aligns with natural language intents is a challenging task, especially in interactive code generation scenarios where most user intents are under-specified."
Focal-Contrast Tree Search Enhances Numerical Reasoning,"Mathematical reasoning is a critical cognitive capability in human intelligence. It has been a persistent challenge in Large Language Model (LLM) development, as the increasing complexity of tasks introduces more uncertainty and error accumulation in LLM reasoning."
Cross-culture Self-Debiasing through Cross-lingual Interactions among Large Language Models,Large language models display unsolved social biases and stereotypes.
Retrieval-Augmented Deductive Reasoning (RADR) Via Structural Decomposition of Legal Analysis,"Natural language understanding, particularly in the domain of legal case precedents, presents significant challenges that impact downstream applications such as legal analysis generation and legal retrieval."
Sampling Q&A Eliminates Hallucinations and Enables Instance Separation of Personal Facts from LLMs,Large Language Models (LLMs) often generate plausible yet false information when prompted for details about individuals with non-recognizable names. We propose a method to eliminate these false statements while simultaneously recognizing that a single name may have multiple consistent sets of personal facts.
Simulating Novice Coding (Mis-)Behaviors with Large Language Models,Generating code that simulates novice programmers' coding (mis-)behaviors is a challenging and unsolved problem in large language models (LLMs).
Guiding Multilingual Storytelling via Question-Answering,"Large language models (LLMs) have demonstrated utility for story planning and generation, with prior work investigating prompting-based approaches for these tasks in English. However, the effectiveness of such methods for multilingual storytelling remains unexplored."
A Culturally-Aware Machine Translation Paradigm,"Large Language Models (LLMs) demonstrate impressive text capabilities in English and other high-resource languages. However, these models fail to generalize their vast language understanding to low-resource languages. This creates exclusion and prevents adoption of new technology in less represented languages, further deepening existing social gaps."
Hallucinations Improve Translations for Low-Resource Languages,This research addresses the following questions:
PolyPrompt: Automating Knowledge Extraction from Multilingual Language Models with Dynamic Prompt Generation,"We address the challenge of generating effective prompts for multilingual large language models (MLLMs). Existing methods like Autoprompt are primarily designed for monolingual contexts, and their application to multilingual settings is not explored. Through PolyPrompt, we aim to extend the capabilities of autoprompting to support dynamic prompts across multiple languages."
Enhancing Code Generation through Property-Based Reasoning,"Current approaches to improving code generation by Large Language Models (LLMs) often rely on unit test generation, which primarily verifies input-output pairs and represents only a surface-level aspect of computational thinking. This method fails to leverage the full potential of property-based reasoning, a key intermediate scaffolding in computational thinking between code intent and the final code."
Mitigating First Name Biases in LLMs by Few-Shot Prompting,"Large Language Models (LLMs) exhibit biased behavior towards individuals based on the race, ethnicity, and gender associated with their first names. It is crucial to alleviate such disparate treatment of first names by LLMs to build inclusive and fair technology. This research aims to study the effectiveness of reducing social biases in LLMs by including various first names in few-shot examples to foster consistent output by LLMs in an implicit manner."
Enhancing Multilingual LLM Performance through Prompt-based Common Sense Integration for Low-resource Languages,"Currently available large language models (LLMs) perform well on multilingual tasks, but lack sufficient training data and contextual awareness, making them difficult to use in low-resource and vernacular languages. Conventional techniques for fine-tuning multilingual datasets require substantial computing power and do not always translate effectively to resource-constrained environments. There is a need for a novel prompting-based technique to enhance LLMs' understanding and performance in these languages by efficiently integrating common sense knowledge."
Chain-of-State Iterative Code Generation via Large Language Models,"Code generation remains challenging for complex problems, even when the generated code is executable. Accurate code generation for intricate tasks is still an area requiring improvement."
"A Two-Man Band: Using LLMs in Conjunction with Code and Knowledge Graphs Improves Clarity, Factuality, and Logical Reasoning","Large Language Models (LLMs) have demonstrated significant success in expressing broad foundational knowledge across various topics. However, they are prone to hallucinating illogical reasoning over that information. Consequently, while LLMs excel at question-answering tasks, they struggle with tasks requiring subtle logical reasoning over text-based prompts."
Chain-of-Quote Prompting Improves Factuality and Attribution in Multi-Hop Reasoning,"Large language models (LLMs) are known to generate fluent but factually incorrect outputs, often termed hallucination. Moreover, it is difficult to attribute the source of their claims. This creates hurdles to effective multi-hop reasoning: LLMs can be misled by their earlier mistakes in the reasoning process, and it is non-trivial to determine which reasoning steps were initially incorrect."
InsideOut - Debiased Emotional Dialogue Generation with Multi-Agent System,Large language model-based dialogue systems struggle with generating contextually appropriate and emotionally rich responses due to emotional biases formed during pre-training and their failure to grasp human nuances and emotional contexts.
Look Before You Leap: Defensive LLM Prompting to Analyze Instruction Intent Against Jailbreaking,"Large Language Model (LLM) jailbreaking, which involves deliberate prompting to circumvent an LLM's safety guardrails and solicit harmful generation, has been a critical issue hindering the wider application of LLMs. Effectively defending against LLM jailbreaking is of great real-world value and impact."
"Algorithm-Supported Programming for Intellectual, Mathematical, and Computational Intensive Code Generation","Large Language Models (LLMs) encounter difficulties when tackling computationally complex programming tasks, particularly those requiring a strong mathematical background and advanced numerical analysis. Experts often need to solve mathematical problems before generating code step-by-step. These types of problems frequently necessitate carefully designed algorithms to achieve optimal performance and efficiency. LLMs struggle to recognize when established mathematical theories should be applied in specific cases."
Improving Code Models through Multi-Agent Debate,"Current code generation models enhance programming productivity but face challenges when integrated directly into projects. Primary issues include: (1) the inability of API-based models to consider the user's machine architecture and environment, leading to errors requiring manual debugging, (2) difficulty in meeting performance requirements such as runtime and memory constraints in a single generation, and (3) generic programming bugs."
Multilingual Prompting with Transliterated Inputs Improves Tokenization Rates and Few-shot Performance,"Current large language models (LLMs) and their tokenizers are predominantly trained on English language data, resulting in poor tokenization rates for low-resource languages, particularly those with non-Latin scripts and rich morphology."
Resolving Ambiguous Translations via Language Model Prompting,"Ambiguity often arises during translation, where one word in the source language may be mapped to several words in the target language, and contextual information or precise linguistic knowledge is required to choose the correct target word for translation. For example, ""wall"" in English may be translated to ""pared"" or ""muro"" in Spanish depending on whether the wall is indoors or outdoors."
Hierarchical Multi-Perspective Prompting Improves Factuality in Large Language Models in Specialized Domains,"Large language models (LLMs) often generate plausible but factually incorrect information, undermining their reliability and usefulness in real-world applications, especially in specialized domains such as biomedicine and history, where accuracy is crucial."
Automatic Jailbreak Prompt Generation for Large Language Models,"Jailbreak prompts can elicit harmful content from Large Language Models (LLMs). However, generating such prompts currently requires manual effort, which limits the scale of safety testing that can be performed before model deployment."
LLM Directed Retrieval Querying for Improving Factuality,"Large language models can generate flexible, long-form language generations, but LLM-generated responses often contain hallucinated or factually inconsistent content. Particularly in high-risk settings, there is a need for methods to improve the factuality of LLMs."
Fishing in an LLM: Theoretically Quantifying Uncertainty with Fisher Information in Large Language Models,"Quantifying uncertainty in large language models frequently relies on heuristics and complex modifications to the training pipeline, which is important for detecting hallucinations in models. Is there a simpler and well-motivated way to achieve this?"
Prompt Evolution for Reducing Negation-Related Errors in Large Language Models,"Large language models struggle with understanding and correctly implementing negation in instructions, particularly in ""do not"" type sentences. This issue affects both general-purpose and specialized language models, and the process of understanding negation in such models is not well understood. The problem is exacerbated when dealing with complex queries that involve multiple negations or when the negation interacts with other linguistic phenomena such as quantifiers, conditionals, or temporal expressions."
Dialect-Aware Machine Translation with Prompted Lexicon Entries as Examples,"Machine translation systems often default to translating into the dominant dialect of a language, neglecting the nuances of regional variants. This approach negatively impacts user experience and potentially marginalizes minority dialects."
ManyChecks: Verifying Math Reasoning from Many Perspectives,Large Language Models (LLMs) often make mistakes when solving mathematical problems on their first attempt. Implementing additional LLM calls to verify and refine their reasoning chains presents a promising strategy to rectify errors and improve the final correctness of LLM's mathematical problem-solving capabilities.
Tree-of-Thought Prompting for Challenging Mathematical Proofs,"While Large Language Models (LLMs) have shown promise in complex mathematical proof automation and discoveries, this field remains under-explored."
FairPrompt: Enhancing Fairness in Multilingual Language Models through Culturally-Aware Prompting Techniques,"Multilingual language models (MLLMs) often exhibit biases and unfair treatment towards languages with fewer resources, resulting in poorer performance and misrepresentation for speakers of these languages. Most fairness evaluations and mitigations focus on high-resource languages like English, overlooking the needs of others. This research aims to develop new prompting techniques that improve the fairness of MLLMs across diverse languages, ensuring equitable performance and representation."
Self-improving Memory Ignites Mathematical Reasoning for Large Language Models,"Mathematical reasoning in large language models (LLMs) requires sophisticated problem decomposition, logical reasoning, and precise calculation. Current approaches often struggle with adaptability and scalability when encountering new problems."
Identifying Optimal Languages for Improving Zero-Shot Low-Resource XNLI Performance,"Performing logical reasoning in low-resource languages is still less accurate than in English, the native language of Large Language Models (LLMs)."
Overcoming Narrow Context Window of LLMs in Requirements Analysis of an Industrial SRS Document,"Large Language Models (LLMs) generate numerous false positives when detecting ambiguities, inconsistencies, and incompleteness issues in Software Requirements Specification (SRS) documents, primarily due to the limited context window in which the LLM focuses."
Enhancing AI Model Reliability by Learning to Express Uncertainty,"Users struggle to reliably utilize AI models, even those capable of producing calibrated confidence estimates, as they lack clarity on when to appropriately accept or rely on AI assistance."
Context-Aware Code Generation: Enhancing Contextual Understanding in Large Language Models for Improved Code Generation,"Current large language models (LLMs) often produce code that lacks context awareness, leading to issues such as incorrect assumptions about variable states, inappropriate use of libraries, and non-optimized logic flows. Enhancing the contextual understanding of code during generation can significantly improve the quality and accuracy of generated code."
Stepwise Uncertainty Estimation in Chain-of-thought,"Large Language Models (LLMs) after Reinforcement Learning from Human Feedback (RLHF) are shown to be poorly calibrated, meaning their output probabilities do not accurately reflect answer uncertainty. This necessitates the development of alternative methods for uncertainty estimation."
Modular Calibration for Long-form Answers,"Calibrating the confidence of Large Language Models (LLMs) when generating long-form answers, such as essays and code, remains an open challenge in the field of natural language processing."
Negative Questioning for Alignment Models to Reduce Hallucinations,"Large language models (LLMs) frequently produce hallucinated responses, and self-verification is challenging due to their tendency to either overconfidently assert or uncritically conform to user inputs. Simple self-validation does not ensure the absence of hallucinations."
Verifying and Improving the Factuality in LMs via Grounded Court Debate,"Language models (LMs) often generate plausible yet incorrect factual information, a phenomenon known as hallucination. A mechanism for verifying and improving the factuality of LM-generated content is critical for building human trust in LMs."
Ensemble of LLMs Attack Safety Classifiers,"Generation of new, diverse, and natural comments that can fool safety classifiers is crucial for future-proofing such classifiers."
Abstaining With Multilingual Knowledge,"Abstaining whenever a language model (LM) is uncertain about its response, in order to reduce hallucinations, is an unsolved problem in Natural Language Processing (NLP)."
