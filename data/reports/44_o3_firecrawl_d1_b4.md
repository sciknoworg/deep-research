# Crafting an Unambiguous Research‐Scoping Process  
*Synthesising 13 recent evidence streams into a practitioner-ready blueprint*  
June 2025 (v1.0)

## 1. Executive Summary
Projects still fail at an alarming clip because the **question to be answered and the conditions of satisfaction are never nailed down**. PMI data (2018) peg the opportunity cost at ≈35 % of projects missing expectations and 33 % of budgets lost to re-work. The research learnings reviewed here converge on a single conclusion: **front-loading a rigorous, multi-modal scoping sequence pays for itself many times over.**

This report curates and integrates *all* 13 evidence clusters supplied (spanning health, industrial decarbonisation, consultancy, questionnaire design, stakeholder engagement, risk alignment and more) and translates them into a single, end-to-end operating model for scoping. The deliverable includes:

• An extensible question toolkit (PCC, CIMO, ECLIPSE, PEO, SPIDER, MLP × agency/structure/meaning)  
• A multi-modal elicitation stack and onboarding cadence  
• Quantitative and qualitative instrument design rules (sample size, confidence levels, item types)  
• A 7-step grey-literature mining protocol  
• Proportionality and risk grids (Goldilocks 3-Part, OECD RBC, audit-scope blueprints)  
• A practical, fill-in-the-blanks **Scoping Canvas** (Appendix A)  
• Future-facing innovations: LLM-powered adaptive forms, real-time stakeholder sentiment heat-maps, and pagination-aware scope bots.

Stakeholder-centred, check-list-driven and technology-augmented: this is the new minimum bar for research scoping in 2025.

---

## 2. Why the “Empty Query” Problem Matters
When the user opens with a slash (`/`) or an otherwise blank brief, the research team must resist the reflex to *start searching anyway.* Instead, we leverage evidence-based scoping frameworks to crystallise:

1. **Problem articulation** – What job is the research hired to do and for whom?  
2. **Intended outcome/deliverable** – Literature review, technology comparison, strategic roadmap, etc.  
3. **Constraints/parameters** – Time window, geographic region, industry, depth, data formats, sample size.  
4. **Success metrics** – How will the sponsor declare victory?  
5. **Too-late-to-use date** – The real deadline, not the stated one.

Neglecting any of these dimensions invites re-work, scope creep and decision paralysis.

---

## 3. Toolkits for Formulating the Core Research Question(s)

### 3.1 Five established health & social-science frameworks
| Framework | Core Template |
|-----------|--------------|
| **PCC**   | Population – Concept – Context  |
| **CIMO**  | Context – Intervention – Mechanism – Outcome |
| **ECLIPSE** | Expectation – Client group – Location – Impact – Professionals – Service category – Evidence |
| **PEO**   | Population – Exposure – Outcome |
| **SPIDER**| Sample – Phenomenon of Interest – Design – Evaluation – Research type |

### 3.2 Industrial decarbonisation upgrade: MLP × Agency/Structure/Meaning
For complex techno-socio transitions, marry the **niche–regime–landscape (MLP)** typology with “agency/structure/meaning” matrices. This explicitly surfaces:

• **Scale** (micro → macro)  
• **Temporality** (historical path, current dynamics, forecast horizon)  
• **Stakeholder lenses** (actors, networks, institutions, narratives).

**Key takeaway** – Pick (or hybridise) a template that matches the problem domain, then layer Population/Process, Scale and Time.

---

## 4. Multi-Modal Elicitation Stack (MMES)
High-performing teams no longer rely on a single kickoff meeting. The **MMES** integrates seven channels:

1. **Stakeholder interviews** (open-ended, divergent)  
2. **Facilitated workshops** (requirements story-mapping)  
3. **Documentation & interface analysis** (contracts, prior reports, dashboards)  
4. **Surveys / questionnaires** (to reach the long-tail of stakeholders)  
5. **Market & competitive scans**  
6. **Brainstorming / design sprints** (to surface latent needs)  
7. **Decision-rights frameworks** – DACI or 3-Amigos to lock ownership.

Early interviews should probe five areas (Nguyen & Widen 2022):

1. *Problem to solve*  2. *Boss’s KPI*  3. *Team hypotheses*  4. *Preferred deliverable format*  5. *Too-late-to-use date*.

---

## 5. Questionnaire & Instrument Design Rules

1. **Workflow** (Scribbr 2023; Qualtrics 2022):
   1. Define objectives  
   2. Craft audience-fit wording  
   3. Optimise length/order  
   4. Pre-test (pilot) → validate reliability.
2. **Item formats:** Nominal, ordinal, 5-/7-point Likert, matrix grids.  
3. **Quant rigour:** Target 95 % confidence, 5–10 % margin of error.  
4. **Sample size:** ≥ 12 for qualitative saturation (Boddy 2016); calculate n for quantitative.  
5. **Administration mode:** Self-administered vs researcher-led—balance reach vs context cues.

### Capstone metric overlay (eCampus Ontario 2024)
• ≥ 10 vetted secondary sources  
• Primary sample ≥ 10 % of population or ≥ 12 interviewees  
• Research paper ≥ 5 pp  
• ≤ 4 weeks per deliverable (≥ 2 weeks on Deliverable #1).

---

## 6. Stakeholder Engagement & Governance

### 6.1 15 Design Principles (Boaz et al., 2018)
Clarify objectives → embed in research-use framework → resource engagement → foster shared values → iterative involvement. *Translation:* build flexibility into the scoping process and budget explicitly for engagement.

### 6.2 Stakeholder Mapping (PMI 2000)
Rate **Interest × Influence**; classify impact (+/–) and risk. High-Interest/High-Influence actors become *Key Stakeholders*—they dictate communication cadence and have veto power over scope changes.

### 6.3 Client-Anxiety Management (Fields 2024)
1) Congrats email, 2) kickoff letter + invoice, 3) info checklist, 4) draft announcement, 5) schedule interviews, 6) implementation plan, 7) formal kickoff meeting.

---

## 7. Systematic Grey-Literature Scoping (4-Channel Template)
1. **Database scrape** (Scopus, PubMed, IEEE Xplore)  
2. **Custom Google CSE** (domain filters)  
3. **Targeted‐site hand search** (NGO portals, think-tanks)  
4. **Expert elicitation** (key informants)

Bias guardrails: restrict Google to first 10 pages, log everything in a tracking sheet; snowball citations only once.

*Case proof*: 2015 Canadian breakfast-program—302 hits → 15 guidelines in < 8 weeks.

---

## 8. Proportionality & Risk Alignment Frameworks

• **Goldilocks 3-Part** – Evidence Level (micro/meso/macro) × Rigour vs Feasibility × Breadth.  
• **OECD RBC** – Sector × Product × Geography × Enterprise size.  
• **Audit-scope blueprints** (TrustCloud 2025) – objectives + risk + regulation + stakeholder + resource matching.

*Use case:* If a sponsor requests a “market map of AI drug-discovery start-ups” but allows only two weeks, the Goldilocks screen will downgrade rigour expectations and restrict breadth to Series A + B firms in two geographies.

---

## 9. Inquiry-Form Taxonomy – Picking the Right Mode

1. **Confirmation inquiry** – verify pre-defined hypotheses.  
2. **Structured inquiry** – supply both Qs & method (ideal for scoping deliverables).  
3. **Guided inquiry** – Qs provided; method open.  
4. **Open inquiry** – participants define both.  

Tool classes: **questionnaires, opinionnaires, checklists, rating scales.** In scoping, *checklists* ensure completeness, while *rating scales* quantify priority.

---

## 10. Quantifying the Pay-Off

PMI’s re-work statistic (33 % of spend) implies a $330 K write-off on a $1 M project. Even a modest scoping regimen costing $25 K that avoids half of that re-work returns ≥ 6 × pay-back. **Economically, rigorous scoping is a dominant strategy.**

---

## 11. Future-Facing & Contrarian Add-Ons (Speculative)

1. **LLM-powered adaptive scoping forms** – Ask 2-3 seed questions; GPT-5 auto-generates the next most informative prompt; iterates until uncertainty converges below threshold.  
2. **Sentiment heat-maps** – Real-time text analytics of stakeholder interviews to flag ambivalence or resistance zones.  
3. **Knowledge-graph visualisers** – Auto-map deliverable scope nodes to data sources and subject-matter experts.  
4. **Pagination-aware scope bots** – Browser extensions that tally *remaining breath* (time/resources) against information entropy, warning analysts of impending overload.

*Flagged as speculation ✓*

---

## 12. Step-by-Step Blueprint

1. **Kickoff (Day 0–1)**  
   • Send congratulations email + info checklist (Fields #1–3).  
   • Attach *Scoping Canvas* (Appendix A) and a calendar link.  
2. **Stakeholder Inventory (Day 1–3)** – Map actors via Interest × Influence; set communication cadence.  
3. **Initial Interviews (Day 3–7)** – Use the 5 core Qs; transcribe & code live.  
4. **Elicitation Workshop (Day 7–10)** – Story-map deliverables, walk through Goldilocks grid.  
5. **Draft Scope Statement (Day 10)** – Populate PCC/CIMO/etc as relevant; circulate for DACI sign-off.  
6. **Questionnaire Design & Pilot (Day 11–16)** – Follow Scribbr 4-stage workflow; pre-test with 3–5 users.  
7. **Grey-Lit Quick-Scan (parallel Day 11–18)** – Use 4-channel template; log hits.  
8. **Scope Lock-In (Day 18)** – Formal sign-off meeting; record “too-late-to-use” date.  
9. **Execution → Delivery** – Time-box per Capstone metrics; maintain weekly check-ins; update scope log on change requests.

---

## 13. Conclusion
The body of evidence across disciplines is unambiguous: **robust, multi-layered scoping is now table-stakes** for any research or consulting engagement. By combining established templates (PCC, CIMO, MLP, etc.), rigorous survey craft, structured stakeholder governance and emerging AI tools, analysts can eliminate the chronic “empty query” failure mode and deliver faster, cheaper, and with fewer unpleasant surprises.

---

## Appendix A – Scoping Canvas (1-Pager)
*(separate fill-able PDF or Miro board)*

1. **Problem Statement (max 100 words)**  
2. **Framework Chosen (circle):** PCC / CIMO / ECLIPSE / PEO / SPIDER / MLP  
3. **Population / Context / Scale / Temp.**  
4. **Desired Deliverable** (format + length)  
5. **Success Metric / Decision Trigger**  
6. **Constraints** – time, budget, geography, data, IP.  
7. **Stakeholder Map Snapshot** (I × In grid)  
8. **Risk & Proportionality Box** (Goldilocks / OECD RBC)  
9. **Data Sources Inventory**  
10. **Locked “Too-Late-to-Use” Date**  
11. **Sign-offs (DACI roles)**  

*End of Report*

## Sources

- https://www.pmi.org/learning/library/stakeholder-analysis-pivotal-practice-projects-8905
- https://teacamp.vdu.lt/mod/book/view.php?id=3235&chapterid=133
- https://dovetail.com/blog/improve-stakeholder-meetings/
- https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-015-0125-0
- https://pageflows.com/resources/ux-research-plan/
- https://ecampusontario.pressbooks.pub/capstoneresources/chapter/research-deliverables/
- https://secure.smore.com/n/r4xtr-structured-inquiry
- https://pmc.ncbi.nlm.nih.gov/articles/PMC10405529/
- https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews
- https://www.davidafields.com/7-steps-to-kick-off-every-consulting-project-perfectly/
- https://health-policy-systems.biomedcentral.com/articles/10.1186/s12961-018-0337-6
- https://seedsforteachers.com/10-ways-to-support-structured-inquiry-in-your-classroom/
- https://www.qualtrics.com/blog/questionnaire/
- https://businessanalystmentor.com/elicitation-technique/
- https://guides.lib.unc.edu/scoping-reviews/protocol
- https://nri-na.com/blog/10-steps-organize-facilitate-successful-requirements-meeting/
- https://carleton.ca/tim/wp-content/uploads/sites/52/2025/03/Guide-to-Produce-Scoping-Reviews-Using-AI-tools-one-file-March-8.pdf
- https://blog.uxtweak.com/ux-research-deliverables/
- https://mneguidelines.oecd.org/OECD-Due-Diligence-Guidance-for-Responsible-Business-Conduct.pdf
- https://userresearchacademy.substack.com/p/treat-stakeholders-like-users
- https://www.hoppier.com/blog/kickoff-meeting
- https://www.atlassian.com/work-management/project-management/project-kickoff
- https://www.sciencedirect.com/science/article/pii/S2214629623000142
- https://www.edvantis.com/blog/requirements-gathering/
- https://libguides.ucmerced.edu/spark_seminars/research_questions_focus
- https://pmc.ncbi.nlm.nih.gov/articles/PMC9580325/
- https://mre-consulting.com/insights/tips-for-a-successful-project-kickoff-meeting/
- https://www.scribbr.com/methodology/questionnaire/
- https://www.answerlab.com/insights/designing-impactful-research-for-stakeholder-needs
- https://dscout.com/people-nerds/project-scoping-framework
- https://www.michiganseagrant.org/lessons/teacher-tools/guide-to-writing-an-inquiry-based-question/
- https://community.trustcloud.ai/docs/grc-launchpad/grc-101/compliance/how-do-i-determine-the-scope-of-an-audit/
- https://spmo.illinois.edu/best-practices/
- https://strategycase.com/how-to-kick-off-a-new-consulting-project/
- https://www.meegle.com/en_us/topics/academic-research-management/managing-research-project-deliverables
- https://www.scribd.com/document/251159769/Inquiry-Forms